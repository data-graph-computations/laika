\relax 
\citation{hadoop}
\citation{graphlab}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A mesh graph where lines correspond to edges and intersections of lines correspond to vertices.}}{1}}
\newlabel{fig_mesh}{{1}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces We see here that compact sets of vertices (represented by the green, red, and blue regions) in 2D space generally map to contiguous sets of Hilbert indices (indices are indicated on the Hilbert curve). The same holds in 3D space. So by ordering the vertices of a mesh graph by Hilbert index, connected vertices, which tend to be nearby in 3D space, are also nearby in the vertex array.}}{2}}
\newlabel{fig_hil_comp}{{2}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A Hilbert curve tracing out the 3D space bounded by the box.}}{2}}
\newlabel{fig_hil3d}{{3}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Dealing with Distributed Execution}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The recursive process by which a 2D Hilbert curve is generated. This process can be generalized to 3D. The red curve is the first recursion level, the blue the second, and the black the third. Each edge of a Hilbert 'U' is turned into a 'U' in the next recursion level, and the space becomes more densely filled as we recurse. Notice that if we trace the black curve from its top left endpoint to its top right endpoint and assume that the Hilbert index is increasing as we trace, and if we map points in space to their nearest points on the Hilbert curve to assign them Hilbert indices, then nearby points are likely to have close Hilbert indices, as illustrated further in Figure 2\hbox {}.}}{2}}
\newlabel{fig_hil2d}{{4}{2}}
\citation{chromatic}
\citation{dag}
\@writefile{toc}{\contentsline {section}{\numberline {III}Fast Execution on Individual Machines}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Graph Representation in Memory}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Scheduling for Parallel Execution}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces A graph colored so that no two neighbors have the same color and so that all vertices of a single color can be updated in parallel.}}{3}}
\newlabel{fig_chrom}{{6}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces A graph whose vertices have been assigned priorities, resulting in the priority scheduling DAG shown at the right.}}{3}}
\newlabel{fig_dag}{{7}{3}}
\citation{tlb}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Organization of graphs in memory on a single machine.}}{4}}
\newlabel{fig_layout}{{5}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Achieving Cache Locality}{4}}
\citation{cilk}
\citation{cilk}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces A mesh whose vertices have been mapped to their nearest corners on a 2D Hilbert curve. Each corner on the Hilbert curve has an index, which becomes the priority of any associated vertices. A priority DAG is induced over the graph as shown. Note that here edges are drawn from low priority vertex to high priority vertex, which is the opposite of the convention used in the text. Edges between vertices with equal Hilbert index have arbitrary direction. Observe that in general vertices are connected to other vertices of nearby Hilbert index, so if the vertex array is sorted by Hilbert index, then neighbor accesses will exhibit good locality. There are also many chains of increasing priority, so neighbors that have been accessed for an update will tend to soon be updated themselves, which is also good for cache efficiency.}}{5}}
\newlabel{fig_hil_prio}{{8}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces A mesh (the same as in Figure 8\hbox {}) whose vertices have been assigned priorities equal to their BFS level, with the red vertex in the bottom left corner being the source of the BFS. The legend on the left shows the color given to vertices of each level. A priority DAG is induced over the graph as shown. Note that here edges are drawn from low priority vertex to high priority vertex, which is the opposite of the convention used in the text. Edges between vertices with equal BFS level have arbitrary direction. Observe that vertices are connected to other vertices of nearby BFS level (within $\pm 1$), so if the vertex array is sorted by BFS level, then neighbor accesses will exhibit good locality assuming that BFS levels are small. There are also many chains of increasing priority, so neighbors that have been accessed for an update will tend to soon be updated themselves, which is also good for cache efficiency.}}{5}}
\newlabel{fig_bfs_prio}{{9}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-D}}Considering Parallelism}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Results}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Evaluation Methodology}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Execution Times and Discussion}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces An illustration of the effect of the parameter $k$, the number of lower-order bits from a node's priority that are made higher-order bits to break long chains of decreasing priority in order to increase parallelism. (Here again edges are drawn from low priority to high priority vertices, contrary to the convention in the text.) Priorities are listed under vertices. In the original graph at the top, there is no parallelism since updates must proceed from left to right, one after another. After reprioritization with $k = 2$, there are now two roots with no dependencies (colored light blue), so their updates (and those of their successors) can be performed in parallel.}}{7}}
\newlabel{fig_k}{{10}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion \& Future Work}{7}}
\bibcite{graphlab}{1}
\bibcite{hadoop}{2}
\bibcite{dag}{3}
\bibcite{chromatic}{4}
\bibcite{cilk}{5}
\bibcite{tlb}{6}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Execution times and performance counter values on a 10M-node mesh graph over three rounds of vertex updates for different execution schedules and vertex orderings. d-cache misses gives the number of data memory requests that could not be served by any level of cache. Serial code was obtained in each instance by simply eliding Cilk keywords. The input order is simply the order of the vertices in the input file passed to the program, which is essentially random from the perspective of cache efficiency. The optimal value of the parameter $k$ was 0 in all but the DAG \& Hilbert case, where it was 18.}}{8}}
\newlabel{fig_result}{{11}{8}}
\@writefile{toc}{\contentsline {section}{References}{8}}
